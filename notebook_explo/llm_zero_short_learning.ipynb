{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.responsabilisation_classes import responsabilisation,deresponsabilisation,neutre\n",
    "\n",
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "telma = pd.read_excel('responsabilisation_test_sample_telma.xlsx')\n",
    "robin = pd.read_excel('responsabilisation_test_sample_robin.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'robin_pred', 'source', 'llm_output_two', 'llm_pred_two'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    if \"déresponsabilisation\" in label:\n",
    "        return 2\n",
    "    elif \"responsabilisation\" in label:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "telma['telma_pred'] = telma['label_telma'].apply(lambda x: encode_label(x.lower() if type(x) == str else \"neutre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = robin[:100].merge(telma[:100], on='text',).dropna(subset=['robin_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5454545454545454\n",
      "F1: 0.5561403932518232\n",
      "Precision: 0.5944719682964197\n",
      "Recall: 0.5454545454545454\n",
      "Specificity: 0.5454545454545454\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "              neutre       0.61      0.66      0.64        41\n",
      "  responsabilisation       0.27      0.47      0.34        15\n",
      "deresponsabilisation       0.69      0.47      0.56        43\n",
      "\n",
      "            accuracy                           0.55        99\n",
      "           macro avg       0.52      0.53      0.51        99\n",
      "        weighted avg       0.59      0.55      0.56        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/env/violent_men/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1523: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "acc = accuracy_score(data['robin_pred'],data['telma_pred'])\n",
    "f1 = f1_score(data['telma_pred'], data['robin_pred'], average='weighted')\n",
    "precision = precision_score(data['telma_pred'], data['robin_pred'], average='weighted')\n",
    "recall = recall_score(data['telma_pred'], data['robin_pred'], average='weighted')\n",
    "specificity = recall_score(data['telma_pred'], data['robin_pred'], average='weighted', pos_label=0)\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "\n",
    "print(classification_report(data['telma_pred'], data['robin_pred'], target_names=['neutre', 'responsabilisation', 'deresponsabilisation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                      precision    recall  f1-score   support\\n\\n              neutre       0.61      0.66      0.64        41\\n  responsabilisation       0.27      0.47      0.34        15\\nderesponsabilisation       0.69      0.47      0.56        43\\n\\n            accuracy                           0.55        99\\n           macro avg       0.52      0.53      0.51        99\\n        weighted avg       0.59      0.55      0.56        99\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(data['telma_pred'], data['robin_pred'], target_names=['neutre', 'responsabilisation', 'deresponsabilisation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_system = f\"\"\" \n",
    "\n",
    "You are a psychiatrist with expertise in violent men. \n",
    "You have received excerpts from testimonies and you have to judge whether the excerpt is neutral or associated with responsibility for the violence.\n",
    "\n",
    "You have 3 cases to distinguish:\n",
    "- Neutral: the excerpt is not about violence or responsibility for violence.\n",
    "- Responsibilization: The person takes responsibility for mistakes and violence.\n",
    "- De-responsibilization: The person denies responsibility for mistakes and violence. They usually try to find excuses or present themselves as victims.\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#neural-chat:7b\n",
    "def from_testimony_to_template_1_example(testimony):\n",
    "    \n",
    "    template = f\"\"\"\n",
    " \n",
    "        \n",
    "        [INST]\n",
    "        Select between the tree classes:\n",
    "        - De-responsibilization\n",
    "        - Neutral\n",
    "        - Responsibilization\n",
    "        \n",
    "\n",
    "        You should ask yourself the following questions:\n",
    "        - Is the excerpt about violence? if no then this is neutral.\n",
    "        - is the person talking about couple relationship? if no then this is neutral.\n",
    "        - Is the person taking responsibility for the violence? if yes then this is responsibilization.\n",
    "        - is the person acknowledging their mistakes? if yes then this is responsibilization.\n",
    "        - Is the person trying to find excuses or presenting themselves as a victim? if yes then this is de-responsibilization.\n",
    "  \n",
    "\n",
    "        \n",
    "        [\\INST]\n",
    "\n",
    "        Here are examples : \n",
    "        excerpt : \"Je savais pas ce qu’est-ce que j’allais faire je suis rentré dans l’armée j’étais un enfant\"\n",
    "        answer: #Neutral\n",
    "        excerpt : \"moi j’ai pas fait j’ai jamais rendu jalouse mais elle oui pis elle entretenait le pattern pis elle voulait dont pas reconnaitre certaines situations\" \n",
    "        answer: #De-responsibilization\n",
    "        excerpt : \"dans le cadre conjugal j’ai j’ai jamais touché à une de mes conjointes physiquement c’est surtout verbalement psychologiquement\"\n",
    "        answer: #Responsibilization\n",
    "        excerpt : \"\"ça j’en j’en étais pas conscient parce qu’il y avait pas de coup physique\",\n",
    "        answer: #Responsibilization\n",
    "\n",
    "        Put your answer in the following format: #answer.\n",
    "        <<<\n",
    "        here is the excerpt: {testimony} \n",
    "        >>>\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    return template\n",
    "\n",
    "def from_testimony_to_template_2_example(testimony):\n",
    "    \n",
    "    template = f\"\"\"\n",
    " \n",
    "        \n",
    "        [INST]\n",
    "        Select between the tree classes:\n",
    "        - Neutral\n",
    "        - Responsibilization\n",
    "        - De-responsibilization\n",
    "\n",
    "        You should ask yourself the following questions:\n",
    "        - Is the excerpt about violence? if no then this is neutral.\n",
    "        - is the person talking about couple relationship? if no then this is neutral.\n",
    "        - Is the person taking responsibility for the violence? if yes then this is responsibilization.\n",
    "        - Is the person regretting their actions? if yes then this is responsibilization.\n",
    "        - is the person acknowledging their mistakes? if yes then this is responsibilization.\n",
    "        - Is the person trying to find excuses? if yes then this is de-responsibilization.\n",
    "        - Is the person presenting themselves as a victim? if yes then this is de-responsibilization.\n",
    "        - Is the person accusing someone else? if yes then this is de-responsibilization.\n",
    "        \n",
    "        [\\INST]\n",
    "\n",
    "        Here are examples : \n",
    "        excerpt : \"Je savais pas ce qu’est-ce que j’allais faire je suis rentré dans l’armée j’étais un enfant\" \n",
    "        answer: #Neutral\n",
    "        excerpt : \"moi j’ai pas fait j’ai jamais rendu jalouse mais elle oui pis elle entretenait le pattern pis elle voulait dont pas reconnaitre certaines situations\" \n",
    "        answer: #De-responsibilization\n",
    "        excerpt : \"dans le cadre conjugal j’ai j’ai jamais touché à une de mes conjointes physiquement c’est surtout verbalement psychologiquement\" \n",
    "        answer: #Responsibilization\n",
    "        excerpt : \"je le sais que je suis impulsif si on m’attaque verbalement j’attaque verbalement c’est c’est c’est automatique essayer de contourner cette mauvaise habitude là ce mauvais comportement là\" \n",
    "        answer: #Reponsibilization\n",
    "        excerpt : \"quand il est parti en ambulance il avait un pouls mais ils ont pas été en mesure de le réanimer\" answer: #Neutral\n",
    "        excerpt : \"is non je m’en rends pas toujours compte parce que j’ai une oreille à 50% de capacité je me rends pas compte quand je commence à parler hyper énervé j’ai le ton de voix qui monte je cri pas mais j’ai le ton de voix qui monte pis j’ai déjà une bonne voix portante faque mais sinon j’ai j’en ai pas de frapper menacer\" \n",
    "        answer: #De-responsibilization\n",
    "        excerpt : \"il faut qu’il y ait des projets communs une vie commune une complicité aimer les mêmes affaires mais pas tout à fait les mêmes affaires en tout cas au moins partager certaines choses\" \n",
    "        answer: #Neutral\n",
    "        excerpt: \"j’ai fait de la violence verbale psychologique parce que j’étais un peu manipulateur aussi\"\n",
    "        answer: #Responsibilization\n",
    "        excerpt: \"moi aussi je pourrais être agressif tu sais pis je lui ai dit puis j’ai brandi le poing devant elle tu sais je pourrais faire ça comme ça pis crier mais je le fais pas tu sais mais en le faisant ça ça l’a traumatisé elle ça l’a marqué tu sais faque j’aurais pas dû faire ça mais je l’ai jamais touché je l’ai jamais frappé tu sais donc EUH\"\n",
    "        answer: #Responsibilization\n",
    "        \n",
    "        Put your answer in the following format: #answer.\n",
    "        <<<\n",
    "        here is the excerpt: {testimony} \n",
    "        >>>\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    return template\n",
    "\n",
    "def from_testimony_to_template_zero_example(testimony):\n",
    "    \n",
    "    template = f\"\"\"\n",
    " \n",
    "        \n",
    "        [INST]\n",
    "        Select between the tree classes:\n",
    "        - Neutral\n",
    "        - Responsibilization\n",
    "        - De-responsibilization\n",
    "\n",
    "        You should ask yourself the following questions:\n",
    "        - Is the excerpt about violence?\n",
    "        - Is the person taking responsibility for the violence?\n",
    "        - Is the person trying to find excuses?\n",
    "        - Is the person presenting themselves as a victim?\n",
    "        \n",
    "        Put your answer in the following format: #answer.\n",
    "        \n",
    "        <<<\n",
    "        here is the excerpt: {testimony} \n",
    "        >>>\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = responsabilisation + deresponsabilisation + neutre\n",
    "data['label'] = ['responsabilisation']*len(responsabilisation) + ['deresponsabilisation']*len(deresponsabilisation) + ['neutre']*len(neutre)\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_llm_analysis(text, label, model = 'neural-chat:7b',example = 1,start_time = None):\n",
    "    print(\"##\" * 50)\n",
    "    if example == 0:\n",
    "        template = from_testimony_to_template_zero_example(text)\n",
    "    elif example == 1:\n",
    "        template = from_testimony_to_template_1_example(text)\n",
    "    elif example == 2:\n",
    "        template = from_testimony_to_template_2_example(text)\n",
    "    else : \n",
    "        raise ValueError(\"example must be 0 or 1\")\n",
    "    r = ollama.generate(model=model, prompt=template,  options = {\"temperature\": 0, \"seed\":42}, keep_alive = \"10s\", system = instruction_system, context = None)\n",
    "    print(\"## True answer: \", label)\n",
    "    print(f\"## {r['response']}\")\n",
    "    if start_time:\n",
    "        if (datetime.now() - start_time).seconds % 120 <= 5: # every 2 minutes we stop for 30 seconds\n",
    "            print(\"sleep 45 \" * 50)\n",
    "            time.sleep(45)\n",
    "        \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print(\"##\" * 50)\n",
    "    #time.sleep(15)\n",
    "    return r['response']\n",
    "\n",
    "\n",
    "#data['llm_output_one'] = data.apply(lambda x: compute_llm_analysis(x['text'], x['label'],example=1), axis = 1)\n",
    "#time.sleep(40)\n",
    "#data['llm_output_two'] = data.apply(lambda x: compute_llm_analysis(x['text'], x['label'],example=2), axis = 1)\n",
    "#time.sleep(40)\n",
    "#data['llm_output_zero'] = data.apply(lambda x: compute_llm_analysis(x['text'], x['label'],example=0), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_llm_output(x):\n",
    "    if \"#Neutral\" in x:\n",
    "        return 0\n",
    "    elif \"#Responsibilization\" in x:\n",
    "        return 1\n",
    "    elif \"#De-responsibilization\" in x:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def norm_label(x):\n",
    "    if x == 'responsabilisation':\n",
    "        return 1\n",
    "    elif x == 'deresponsabilisation':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['llm_pred_one'] = data['llm_output_one'].apply(lambda x: norm_llm_output(x))\n",
    "data['llm_pred_two'] = data['llm_output_two'].apply(lambda x: norm_llm_output(x))\n",
    "data['llm_pred_zero'] = data['llm_output_zero'].apply(lambda x: norm_llm_output(x))\n",
    "data['true'] = data['label'].apply(lambda x: norm_label(x))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "\n",
    "print(f1_score(data['true'], data['llm_pred_one'], average = 'weighted'))\n",
    "print(accuracy_score(data['true'], data['llm_pred_one']))\n",
    "print(classification_report(data['true'], data['llm_pred_one']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5393322014714205\n",
      "0.6129032258064516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.50      0.10      0.17        10\n",
      "           2       0.61      0.93      0.74        15\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.59      0.57      0.52        31\n",
      "weighted avg       0.58      0.61      0.54        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(data['true'], data['llm_pred_zero'], average = 'weighted'))\n",
    "print(accuracy_score(data['true'], data['llm_pred_zero']))\n",
    "print(classification_report(data['true'], data['llm_pred_zero']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6228878648233487\n",
      "0.6774193548387096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       1.00      0.20      0.33        10\n",
      "           2       0.62      0.87      0.72        15\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.79      0.69      0.64        31\n",
      "weighted avg       0.77      0.68      0.62        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(data['true'], data['llm_pred_one'], average = 'weighted'))\n",
    "print(accuracy_score(data['true'], data['llm_pred_one']))\n",
    "print(classification_report(data['true'], data['llm_pred_one']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7194083588770496\n",
      "0.7419354838709677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.80      0.40      0.53        10\n",
      "           2       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.75      0.72      0.71        31\n",
      "weighted avg       0.75      0.74      0.72        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(data['true'], data['llm_pred_two'], average = 'weighted'))\n",
    "print(accuracy_score(data['true'], data['llm_pred_two']))\n",
    "print(classification_report(data['true'], data['llm_pred_two']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>duration</th>\n",
       "      <th>interactions</th>\n",
       "      <th>comments</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_Q1</th>\n",
       "      <th>text_Q2</th>\n",
       "      <th>text_Q3</th>\n",
       "      <th>text_Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P34</td>\n",
       "      <td>1620</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q1'}, {...</td>\n",
       "      <td>[Transcription 34 , 27 min , Énervant à retran...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q1'}, {...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q2'}, {...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q3'}, {...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q4'}, {...</td>\n",
       "      <td>france</td>\n",
       "      <td>oui donc pour moi c’est le décès de mon petit...</td>\n",
       "      <td>oui donc pour moi c’est le décès de mon petit...</td>\n",
       "      <td>BAH EUH non parce que je vois pas idées suici...</td>\n",
       "      <td>Alors au niveau du couple je maintiens que ça...</td>\n",
       "      <td>BAH très bien c’est bête j’aurais dû vous l’a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P16</td>\n",
       "      <td>1560</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q1'}, {...</td>\n",
       "      <td>[26 min – 11 bizarres en 15 min ]</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' Q1'}, {...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' ouais o...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' ok Q3'}...</td>\n",
       "      <td>[{'speaker': 'experimenter', 'text': ' ok Q4'}...</td>\n",
       "      <td>france</td>\n",
       "      <td>EUH BAH l’é_ l’évènement EUH excusez-moi c’es...</td>\n",
       "      <td>EUH BAH l’é_ l’évènement EUH excusez-moi c’es...</td>\n",
       "      <td>des auto-violences non j’ai jamais fait ça\\n ...</td>\n",
       "      <td>et att_ pour le plaisir c’est pour ça que qua...</td>\n",
       "      <td>BAH j’ai pensé que c’était c’était c’était AL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code duration                                       interactions  \\\n",
       "0  P34     1620  [{'speaker': 'experimenter', 'text': ' Q1'}, {...   \n",
       "1  P16     1560  [{'speaker': 'experimenter', 'text': ' Q1'}, {...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  [Transcription 34 , 27 min , Énervant à retran...   \n",
       "1                  [26 min – 11 bizarres en 15 min ]   \n",
       "\n",
       "                                                  Q1  \\\n",
       "0  [{'speaker': 'experimenter', 'text': ' Q1'}, {...   \n",
       "1  [{'speaker': 'experimenter', 'text': ' Q1'}, {...   \n",
       "\n",
       "                                                  Q2  \\\n",
       "0  [{'speaker': 'experimenter', 'text': ' Q2'}, {...   \n",
       "1  [{'speaker': 'experimenter', 'text': ' ouais o...   \n",
       "\n",
       "                                                  Q3  \\\n",
       "0  [{'speaker': 'experimenter', 'text': ' Q3'}, {...   \n",
       "1  [{'speaker': 'experimenter', 'text': ' ok Q3'}...   \n",
       "\n",
       "                                                  Q4  source  \\\n",
       "0  [{'speaker': 'experimenter', 'text': ' Q4'}, {...  france   \n",
       "1  [{'speaker': 'experimenter', 'text': ' ok Q4'}...  france   \n",
       "\n",
       "                                                text  \\\n",
       "0   oui donc pour moi c’est le décès de mon petit...   \n",
       "1   EUH BAH l’é_ l’évènement EUH excusez-moi c’es...   \n",
       "\n",
       "                                             text_Q1  \\\n",
       "0   oui donc pour moi c’est le décès de mon petit...   \n",
       "1   EUH BAH l’é_ l’évènement EUH excusez-moi c’es...   \n",
       "\n",
       "                                             text_Q2  \\\n",
       "0   BAH EUH non parce que je vois pas idées suici...   \n",
       "1   des auto-violences non j’ai jamais fait ça\\n ...   \n",
       "\n",
       "                                             text_Q3  \\\n",
       "0   Alors au niveau du couple je maintiens que ça...   \n",
       "1   et att_ pour le plaisir c’est pour ça que qua...   \n",
       "\n",
       "                                             text_Q4  \n",
       "0   BAH très bien c’est bête j’aurais dû vous l’a...  \n",
       "1   BAH j’ai pensé que c’était c’était c’était AL...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus  = pd.read_hdf('/home/robin/Data/Etude_telma/20240227_text_database.h5', key = \"df\")\n",
    "corpus.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def split_text_with_overlap(text,code, k = 75, p = 10):\n",
    "    words = text.split()\n",
    "    sequences = []\n",
    "    for i in range(0, len(words) - k + 1, k - p):\n",
    "        sequences.append(\" \".join(words[i:i + k]))\n",
    "    return sequences, [code]*len(sequences)\n",
    "\n",
    "\n",
    "corpus['sequence_list'], corpus['code_list'] = \\\n",
    "zip(*corpus.apply(lambda x :split_text_with_overlap(x['text_Q3'],x.code, k = 75, p = 10),axis=1).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 786)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['text'] = flatten_list(corpus['sequence_list'].tolist())\n",
    "test['source'] = flatten_list(corpus['code_list'].tolist())\n",
    "test_sample = test.sample(n=200).reset_index(drop=True)\n",
    "len(test_sample), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "test_sample['llm_output_two'] = test_sample['text'].apply(lambda x: compute_llm_analysis(x, 'unknown',example=2,start_time = start_time))\n",
    "test_sample['llm_pred_two'] = test_sample['llm_output_two'].apply(lambda x: norm_llm_output(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample.to_csv('responsabilisation_test_sample.csv',index = False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['llm_output_norm'] = test['llm_output_two'].apply(norm_llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je suis quelqu’un je suis quelqu’un qui aime beaucoup le sexe pis elle aussi d’ailleurs elle aussi d’ailleurs mais je voulais tout le temps plus j’avais faim j’en voulait tout le temps pis des bout avant c’est important ce que tu vas entendre avant à la à la elle m’avait',\n",
       " 'ALL non une fois il s’est reproduit qu’une fois c’est du harcèlement par téléphone j’ai dû aller une fois devant chez elle mais c’est pareil aussi EUH elle avait le le c’est ça c’est que PS c’est c’est c’est con à dire mais EUH par exemple j’allais / on discutait',\n",
       " 'sur moi c’est comme si PS je sais pas elle était sortie elle est revenue j’ai rien compris j’ai absolument rien compris Non elle s’est jetée sur moi et là elle m’a bousculé jusqu’au ALL à l’intérieur de la de la chambre pour aller me cogner contre les effets là-bas',\n",
       " 'voulait pas l’entendre pis là après ça elle elle s’est mis comme à je sais pas ce qu’elle me disait mais elle me chia_ elle me chialait après elle me chicanait pis elle elle levait le ton j’étais plus capable je lui disais d’arrêter pis ça continuait ça continuait ça',\n",
       " 'personne en fait essayait de me dominer ouais me dominer tandis que moi comme j’ai déjà expliqué dans dans plusieurs documents moi je suis quelqu’un moi je me suis élevé moi-même donc ALL quand je sais quelqu’un il me dit ou j’aime pas quelqu’un il me dicte il faut que',\n",
       " 'si c’était à cause d’elle que la police était arrivée alors que rien à voir elle subit comme moi elle subit comme moi à l’origine elle voulait juste que je baisse le son elle était pas là pour faire un scénario américain PS mais bon après ouais BAH quand la',\n",
       " 'coin là pis je stressais XXX que je voyais pas l’auto pis tu sais ils sortaient pas souvent ils sortaient admettons une fois par mois tu sais pour les soupers ou / pis là quand je voyais l’auto virer rentrer dans le driveway là je me couchais PS c’est ça',\n",
       " 'cette spirale où finalement la gravité augmente aussi et EUH ALL PS (EXPIRATION) PS l’envie de de régner par la peur en fait l’envie d’obtenir ce qu’on veut par la peur EUH ALL comme Poutine on va dire et voilà et en fait on y arrive pas comme lui c’est',\n",
       " 'porte d’entrée des câlins des bisous j’enlevais mes chaussures les courses étaient là dans l’entrée et là du coup j’ai emmené les courses et j’ai dit « salut » BAH elle m’a pas répondu je suis allé déposer les courses après je suis venu dans la chambre je suis venu',\n",
       " 'compte participatif on versait chacun une somme d’argent tous les mois pour EUH entretenir le foyer payer les crédits et fin bon EUH bah moi innocemment on l’avait ouvert ensemble mais je m’en suis jamais occupé parce que moi je continuais les travaux de la maison je faisais mon truc']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['llm_output_norm']==2].sample(10)['text'].to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
